{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1249c874",
   "metadata": {},
   "source": [
    "# Job Posting Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbabd9a",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02bb3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup \n",
    "import pymongo\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69b98eb",
   "metadata": {},
   "source": [
    "### General Fucntions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aa1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdriver ():\n",
    "    path=r'chromedriver.exe'\n",
    "    #driver = webdriver.Chrome(executable_path='/Users/Sripriya Srinivasan/Downloads/chromedriver_win32/chromedriver')\n",
    "    driver = webdriver.Chrome(executable_path=path)\n",
    "    driver.implicitly_wait(10)\n",
    "    driver.set_script_timeout(120)\n",
    "    driver.set_page_load_timeout(30)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cb5794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writePage(fname,content):\n",
    "    with open(fname, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(str(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b9df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file (name):\n",
    "    HTMLFile = open(name, \"rb\")\n",
    "    htmlfiledata = HTMLFile.read()\n",
    "    return BeautifulSoup(htmlfiledata, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503a1d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_mongodb (db_name, collection_name):\n",
    "    client = pymongo.MongoClient(\"mongodb://localhost:27017\")\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ead3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadWebsiteData (url):\n",
    "    try:\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        page = requests.get(url,headers=headers)\n",
    "        # Create a beautifulsoup object \n",
    "        return BeautifulSoup(page.text, 'lxml')\n",
    "    except :\n",
    "        print(\"Error connecting to website\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a627af06",
   "metadata": {},
   "source": [
    "## LinkedIn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387384f2",
   "metadata": {},
   "source": [
    "### Infinite Scroll and Save all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6691fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "datascience_url = \"https://www.linkedin.com/jobs/search?keywords=data%20scientist&location=california&geoId=&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0\"\n",
    "dataanalyst_url = \"https://www.linkedin.com/jobs/search/?currentJobId=3489147354&geoId=102095887&keywords=Data%20Analyst&location=California%2C%20United%20States&refresh=true\"\n",
    "businessanalyst_url = \"\"\n",
    "\n",
    "# Change assignment for scraping different roles\n",
    "url = datascience_url\n",
    "\n",
    "driver = getdriver()\n",
    "driver.get(url)\n",
    "time.sleep(2)  \n",
    "scroll_pause_time = 1 \n",
    "screen_height = driver.execute_script(\"return window.screen.height;\")\n",
    "i = 1\n",
    "link_num = 1\n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollTo(0, {screen_height}*{i});\".format(screen_height=screen_height, i=i))  \n",
    "    i += 1\n",
    "    time.sleep(scroll_pause_time)\n",
    "    scroll_height = driver.execute_script(\"return document.body.scrollHeight;\") \n",
    "    try:\n",
    "        button = driver.find_elements(\"xpath\",\"//*[contains(text(), 'See more jobs')]\")\n",
    "        button[0].click()\n",
    "    except:\n",
    "        print(\"Button not found\")\n",
    "    if (screen_height) * i > scroll_height:\n",
    "        break\n",
    "writePage('linkedin_search_results',driver.page_source)\n",
    "links = driver.find_elements(\"css selector\",\"a.base-card__full-link.absolute\")\n",
    "files_list = []\n",
    "for link in links:\n",
    "    fname = 'ds_'+str(link_num)\n",
    "    files_list.append(fname)\n",
    "    writePage(fname,loadWebsiteData(link.get_attribute('href')))\n",
    "    link_num = link_num + 1\n",
    "    \n",
    "print(len(links))\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873fe3cc",
   "metadata": {},
   "source": [
    "### Iterate through saved files and parse information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdd91c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_posting_dict = {}\n",
    "for file in files_list :\n",
    "    job_soup = read_file(file)\n",
    "    role = job_soup.select(\"h1\")[0].text\n",
    "    company = job_soup.select(\"a.topcard__org-name-link\")[0].text.strip()\n",
    "    location =  job_soup.select(\"span.topcard__flavor.topcard__flavor--bullet\")[0].text.strip()\n",
    "    info = job_soup.select(\"div.show-more-less-html__markup\")[0].text.strip()\n",
    "\n",
    "    fields = job_soup.select(\"h3.description__job-criteria-subheader\")\n",
    "    values = job_soup.select(\"span.description__job-criteria-text.description__job-criteria-text--criteria\")\n",
    "    extra_info = {}\n",
    "    for i in range(0,len(fields)):\n",
    "        extra_info[fields[i].text.strip()] = values[i].text.strip()\n",
    "    posting = {'Job Role':role,'Company':company,'Location':location,'Job Description':info,'Additional Details':extra_info}\n",
    "    job_posting_dict.append(posting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = connect_mongodb ('job_postings', 'jobs')\n",
    "collection.insert_many(job_posting_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
